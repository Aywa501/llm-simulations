Testing whether modern LLMs can reliably replicate results from classic and recent behavioral economics experiments (“homo silicus”). We pull the original experiment text from pre-registered studies, have an LLM act as survey respondents across treatment and control groups, convert its outputs into the same numeric variables as the original studies, and then statistically compare LLM results to human data.
Proof of concept: replicated three effects (conformity, loss aversion, and tax compliance) using a lightweight GPT model. Ran with ~500 simulated participants per group, The main outcome is whether the LLM reproduces the direction, magnitude, and distribution of the original treatment effects. (mixed results, some signal maybe)
Now doing with a wider batch of studies, in the process of testing out scraping pipeline

Full doc here: https://docs.google.com/document/d/1vCyfUhEbOf_YhtKaQOY9ICtdfhbauUEyaB0uIcXun-M/edit?usp=sharing
