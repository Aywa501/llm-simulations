{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "!pip install pandas numpy nltk spacy\n",
        "\n",
        "# Install spaCy model\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Libraries for semantic metrics\n",
        "!pip install bert-score\n",
        "!pip install bleurt\n",
        "!pip install moverscore\n",
        "\n",
        "# Download BLEURT checkpoint\n",
        "!wget https://storage.googleapis.com/bleurt-data/BLEURT-20.zip\n",
        "!unzip BLEURT-20.zip"
      ],
      "metadata": {
        "id": "Kohyhae2DuGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "import string\n",
        "from collections import defaultdict\n",
        "\n",
        "# import semantic libraries after pip installs\n",
        "try:\n",
        "    from bert_score import score as bert_score_calc\n",
        "except ImportError:\n",
        "    print(\"bert_score not found. Please run 'pip install bert_score'\")\n",
        "\n",
        "try:\n",
        "    from bleurt.score import BleurtScorer\n",
        "except ImportError:\n",
        "    print(\"bleurt not found. Please run 'pip install bleurt'\")\n",
        "\n",
        "try:\n",
        "    from moverscore import get_idf_dict, word_mover_score\n",
        "except ImportError:\n",
        "    print(\"moverscore not found. Please run 'pip install moverscore'\")\n",
        "\n",
        "\n",
        "# one time nltk downloads\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# load nlp models\n",
        "# load a spaCy model. 'en_core_web_sm' is fast and light. 'en_core_web_trf' is more accurate but much slower.\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "except OSError:\n",
        "    print(\"Spacy model 'en_core_web_sm' not found.\")\n",
        "    print(\"Please run: python -m spacy download en_core_web_sm\")\n",
        "    nlp = None\n",
        "\n",
        "# Load BLEURT scorer\n",
        "# IMPORTANT: update path to where i unzipped \"BLEURT-20\"\n",
        "BLEURT_CHECKPOINT_PATH = \"./BLEURT-20\"\n",
        "try:\n",
        "    bleurt_scorer = BleurtScorer(BLEURT_CHECKPOINT_PATH)\n",
        "except (IOError, NameError):\n",
        "    print(f\"BLEURT checkpoint not found at {BLEURT_CHECKPOINT_PATH}\")\n",
        "    print(\"Please download and unzip it as per the setup instructions.\")\n",
        "    bleurt_scorer = None\n",
        "\n",
        "\n",
        "# helper function for lexical preprocessing\n",
        "def preprocess_text_for_lexical(text: str) -> list:\n",
        "    \"\"\"\n",
        "    Lowercase, remove punctuation, remove stopwords, and tokenize.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text)\n",
        "    return [word for word in tokens if word not in stop_words and word.isalpha()]\n",
        "\n",
        "# METHOD 1: Syntactic Complexity (spaCy-based proxies)\n",
        "def get_syntactic_complexity(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates syntactic complexity features using spaCy.\n",
        "\n",
        "    This provides proxies for MLC (Mean Length of Clause) and\n",
        "    CN/C (Complex Nominals per Clause).\n",
        "\n",
        "    Metrics:\n",
        "    - mean_sentence_length: Avg. # of tokens per sentence.\n",
        "    - mean_noun_chunk_length: Avg. # of tokens per noun chunk (proxy for nominal elaboration).\n",
        "    - sub_clauses_per_sentence: Avg. # of subordinating conjunctions ('mark' dependency)\n",
        "      per sentence (proxy for clausal complexity).\n",
        "    \"\"\"\n",
        "    if nlp is None:\n",
        "        raise EnvironmentError(\"spaCy model is not loaded. Please check setup.\")\n",
        "\n",
        "    results = []\n",
        "    for text in df[col]:\n",
        "        doc = nlp(text)\n",
        "\n",
        "        num_sentences = len(list(doc.sents))\n",
        "        num_tokens = len([t for t in doc if not t.is_punct])\n",
        "        noun_chunks = list(doc.noun_chunks)\n",
        "        num_sub_clauses = len([t for t in doc if t.dep_ == 'mark'])\n",
        "\n",
        "        if num_sentences > 0:\n",
        "            mean_sentence_length = num_tokens / num_sentences\n",
        "            sub_clauses_per_sentence = num_sub_clauses / num_sentences\n",
        "        else:\n",
        "            mean_sentence_length = 0\n",
        "            sub_clauses_per_sentence = 0\n",
        "\n",
        "        if len(noun_chunks) > 0:\n",
        "            mean_noun_chunk_length = sum(len(nc) for nc in noun_chunks) / len(noun_chunks)\n",
        "        else:\n",
        "            mean_noun_chunk_length = 0\n",
        "\n",
        "        results.append({\n",
        "            'mean_sentence_length': mean_sentence_length,\n",
        "            'mean_noun_chunk_length': mean_noun_chunk_length,\n",
        "            'sub_clauses_per_sentence': sub_clauses_per_sentence\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# METHOD 2: Lexical Richness (TTR, Hapax Rate)\n",
        "def get_lexical_richness(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates lexical richness features: TTR and Hapax Rate.\n",
        "\n",
        "    Metrics:\n",
        "    - ttr (Type-Token Ratio): Unique tokens / Total tokens.\n",
        "    - hapax_rate (Hapax Legomena Rate): Tokens appearing only once / Total tokens.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for text in df[col]:\n",
        "        tokens = preprocess_text_for_lexical(text)\n",
        "        total_tokens = len(tokens)\n",
        "\n",
        "        if total_tokens == 0:\n",
        "            results.append({'ttr': 0, 'hapax_rate': 0})\n",
        "            continue\n",
        "\n",
        "        num_unique_tokens = len(set(tokens))\n",
        "        ttr = num_unique_tokens / total_tokens\n",
        "\n",
        "        freq_dist = FreqDist(tokens)\n",
        "        num_hapaxes = len(freq_dist.hapaxes())\n",
        "        hapax_rate = num_hapaxes / total_tokens\n",
        "\n",
        "        results.append({'ttr': ttr, 'hapax_rate': hapax_rate})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# METHOD 3: BERTScore\n",
        "def get_bertscore(df: pd.DataFrame, col: str, reference_text: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates BERTScore (Precision, Recall, F1) against a reference text.\n",
        "    \"\"\"\n",
        "    if 'bert_score_calc' not in globals():\n",
        "        raise EnvironmentError(\"bert_score library not loaded.\")\n",
        "\n",
        "    candidates = df[col].tolist()\n",
        "    # Create a list of the same reference text for all candidates\n",
        "    references = [reference_text] * len(candidates)\n",
        "\n",
        "    P, R, F1 = bert_score_calc(candidates, references, lang='en', model_type='bert-base-uncased')\n",
        "\n",
        "    results = {\n",
        "        'bertscore_precision': P.numpy(),\n",
        "        'bertscore_recall': R.numpy(),\n",
        "        'bertscore_f1': F1.numpy()\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# METHOD 4: BLEURT\n",
        "def get_bleurt(df: pd.DataFrame, col: str, reference_text: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates the BLEURT score against a reference text.\n",
        "    Uses the pre-loaded BLEURT-20 scorer.\n",
        "    \"\"\"\n",
        "    if bleurt_scorer is None:\n",
        "        raise EnvironmentError(\"BLEURT scorer not loaded. Please check checkpoint path.\")\n",
        "\n",
        "    candidates = df[col].tolist()\n",
        "    references = [reference_text] * len(candidates)\n",
        "\n",
        "    scores = bleurt_scorer.score(references=references, candidates=candidates)\n",
        "\n",
        "    return pd.DataFrame({'bleurt_score': scores})\n",
        "\n",
        "# METHOD 5: MoverScore\n",
        "def get_moverscore(df: pd.DataFrame, col: str, reference_text: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates MoverScore against a reference text.\n",
        "    \"\"\"\n",
        "    if 'word_mover_score' not in globals():\n",
        "        raise EnvironmentError(\"moverscore library not loaded.\")\n",
        "\n",
        "    candidates = df[col].tolist()\n",
        "    references = [reference_text] * len(candidates)\n",
        "\n",
        "    # MoverScore requires IDF dictionaries.\n",
        "    # Create them from the corpus itself (candidates + references).\n",
        "    all_texts = candidates + references\n",
        "    idf_dict = get_idf_dict(all_texts)\n",
        "\n",
        "    # Set stop_words=[] because MoverScore's default list is large\n",
        "    # and may remove important words for semantic comparison.\n",
        "    scores = word_mover_score(\n",
        "        references,\n",
        "        candidates,\n",
        "        idf_dict,\n",
        "        idf_dict,\n",
        "        stop_words=[],\n",
        "        n_gram=1,\n",
        "        remove_subwords=True,\n",
        "        batch_size=48 # Adjust batch size based on your GPU/CPU memory\n",
        "    )\n",
        "\n",
        "    return pd.DataFrame({'moverscore': scores})"
      ],
      "metadata": {
        "id": "8LHdOqjM3VCA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}